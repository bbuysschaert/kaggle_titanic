# Titanic challenge on Kaggle

Repository with the code used to tackle the [Titanic challenge on Kaggle](https://www.kaggle.com/competitions/titanic/overview).

This exercise has different goals:
1. Familiarize yourself with Kaggle and the way of submitting predictions.
2. Improve upon your knowledge of different ML packages in Python and PySpark
3. Understand the differences between different methods of working (for example, Python vs PySpark vs sklearn pipelines)
4. Have some code snippets ready for the future to work on this (for example, work with mlflow, perform imputations of data, ...)

This exercise has not the goal of having the best predictions possible...


## To do:
- [] Update and include requirements.txt
- [] Clean the code of the basicpython folder
- [] Transition from function-based code to OOP and include an sklearnpipeline
- [] Transition from Python to PySpark for the data preparation
- [] Set up an mlflow environment and include logging of the experiments
- [] Try different ML models and log these as different experiments
- [] Include hyperparameter optimizations and log these
- [] Include documentation in Sphinx or the like
- [] Update documentation in Github automatically through a CI pipeline
- [] Include automated submissions to Kaggle


## Continous to do:
- [] Understand the features created and which should be included in the ML model
- [] Update documentation throughout the code